#!/usr/bin/env python3
"""
Automated Settings Menu Test
Tests all settings menu functionality without manual interaction
"""

import os
import sys
import tempfile
import shutil
from pathlib import Path

# Add src to path
sys.path.insert(0, 'src')

from dotenv import load_dotenv

# Test results tracking
tests_passed = 0
tests_failed = 0
tests_total = 0

def print_test(name):
    """Print test name"""
    print(f"\nüß™ Testing: {name}")

def pass_test(name):
    """Mark test as passed"""
    global tests_passed, tests_total
    tests_passed += 1
    tests_total += 1
    print(f"‚úÖ PASS: {name}")

def fail_test(name, error):
    """Mark test as failed"""
    global tests_failed, tests_total
    tests_failed += 1
    tests_total += 1
    print(f"‚ùå FAIL: {name}")
    print(f"   Error: {error}")

def test_env_file_operations():
    """Test .env file reading and updating"""
    print("\n" + "="*60)
    print("üìù Testing .env File Operations")
    print("="*60)
    
    # Test 1: Load .env file
    print_test("Load .env file")
    try:
        load_dotenv()
        required_vars = ['SAVE_PATH', 'OUTPUT_FORMAT', 'WHISPER_MODEL', 'OLLAMA_MODEL']
        missing = [var for var in required_vars if not os.getenv(var)]
        
        if not missing:
            pass_test(".env file loads successfully")
        else:
            fail_test(".env file incomplete", f"Missing: {', '.join(missing)}")
    except Exception as e:
        fail_test(".env file loading", str(e))
    
    # Test 2: Read all settings values
    print_test("Read all configuration values")
    try:
        config = {
            'SAVE_PATH': os.getenv('SAVE_PATH'),
            'OUTPUT_FORMAT': os.getenv('OUTPUT_FORMAT', 'md'),
            'WHISPER_MODEL': os.getenv('WHISPER_MODEL', 'small'),
            'WHISPER_LANGUAGE': os.getenv('WHISPER_LANGUAGE', 'auto'),
            'OLLAMA_MODEL': os.getenv('OLLAMA_MODEL'),
            'AUTO_COPY': os.getenv('AUTO_COPY', 'false'),
            'AUTO_OPEN': os.getenv('AUTO_OPEN', 'false'),
            'AUTO_METADATA': os.getenv('AUTO_METADATA', 'false'),
            'AUTO_CLEANUP_AUDIO': os.getenv('AUTO_CLEANUP_AUDIO', 'true'),
            'SILENCE_DURATION_SECONDS': os.getenv('SILENCE_DURATION_SECONDS', '120'),
            'DEFAULT_MIC_DEVICE': os.getenv('DEFAULT_MIC_DEVICE', '-1'),
            'STREAMING_BUFFER_SIZE_SECONDS': os.getenv('STREAMING_BUFFER_SIZE_SECONDS', '300'),
            'STREAMING_MIN_SEGMENT_DURATION': os.getenv('STREAMING_MIN_SEGMENT_DURATION', '30'),
            'STREAMING_TARGET_SEGMENT_DURATION': os.getenv('STREAMING_TARGET_SEGMENT_DURATION', '60'),
            'STREAMING_MAX_SEGMENT_DURATION': os.getenv('STREAMING_MAX_SEGMENT_DURATION', '90'),
            'STREAMING_VERBOSE': os.getenv('STREAMING_VERBOSE', 'false'),
            'COMMAND_NAME': os.getenv('COMMAND_NAME', 'rec'),
            'OLLAMA_API_URL': os.getenv('OLLAMA_API_URL', 'http://localhost:11434/api/generate'),
            'OLLAMA_TIMEOUT': os.getenv('OLLAMA_TIMEOUT', '180'),
            'OLLAMA_MAX_CONTENT_LENGTH': os.getenv('OLLAMA_MAX_CONTENT_LENGTH', '32000'),
        }
        
        print(f"   Loaded {len(config)} configuration values")
        pass_test("All configuration values readable")
    except Exception as e:
        fail_test("Read configuration values", str(e))

def test_update_env_setting():
    """Test update_env_setting function"""
    print("\n" + "="*60)
    print("üîß Testing Settings Update Function")
    print("="*60)
    
    # Create a temporary .env file for testing
    with tempfile.NamedTemporaryFile(mode='w', suffix='.env', delete=False) as tmp:
        tmp.write("TEST_VAR=old_value\n")
        tmp.write("ANOTHER_VAR=keep_this\n")
        tmp_path = tmp.name
    
    try:
        # Test 1: Import update function
        print_test("Import update_env_setting function")
        try:
            from settings import update_env_setting
            pass_test("update_env_setting imports successfully")
        except Exception as e:
            fail_test("Import update_env_setting", str(e))
            return
        
        # Test 2: Update existing value
        print_test("Update existing environment variable")
        try:
            # Temporarily override .env path for testing
            original_env = os.path.join(os.getcwd(), '.env')
            
            # Read original .env
            with open(original_env, 'r') as f:
                original_content = f.read()
            
            # This is a read-only test - we won't actually modify .env
            # Just verify the function exists and has correct signature
            import inspect
            sig = inspect.signature(update_env_setting)
            params = list(sig.parameters.keys())
            
            if 'key' in params and 'value' in params:
                pass_test("update_env_setting has correct signature")
            else:
                fail_test("update_env_setting signature", f"Expected (key, value), got {params}")
        except Exception as e:
            fail_test("Validate update function", str(e))
    
    finally:
        # Clean up temp file
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

def test_settings_menu_import():
    """Test that settings menu can be imported"""
    print("\n" + "="*60)
    print("üìã Testing Settings Menu Imports")
    print("="*60)
    
    # Test 1: Import main settings menu
    print_test("Import settings_menu")
    try:
        from settings import settings_menu
        pass_test("settings_menu imports successfully")
    except Exception as e:
        fail_test("Import settings_menu", str(e))
    
    # Test 2: Import all submenu functions
    print_test("Import all submenu functions")
    try:
        from settings import (
            transcription_settings,
            output_settings,
            ai_settings,
            audio_settings,
            advanced_performance_settings,
            command_settings,
            uninstall_settings
        )
        pass_test("All 7 submenu functions import successfully")
    except Exception as e:
        fail_test("Import submenu functions", str(e))
    
    # Test 3: Import list_audio_devices
    print_test("Import list_audio_devices")
    try:
        from settings import list_audio_devices
        pass_test("list_audio_devices imports successfully")
    except Exception as e:
        fail_test("Import list_audio_devices", str(e))

def test_audio_device_listing():
    """Test audio device enumeration"""
    print("\n" + "="*60)
    print("üé§ Testing Audio Device Functions")
    print("="*60)
    
    print_test("List audio devices")
    try:
        from settings import list_audio_devices
        devices = list_audio_devices()
        
        if devices is not None:
            print(f"   Found {len(devices)} audio devices")
            pass_test(f"Audio device listing works ({len(devices)} devices)")
        else:
            fail_test("Audio device listing", "No devices returned")
    except Exception as e:
        # Audio device listing can fail in headless/CI environments
        print(f"   ‚ö†Ô∏è  Note: {e}")
        pass_test("Audio device function exists (may not work in this environment)")

def test_configuration_validation():
    """Test configuration value validation"""
    print("\n" + "="*60)
    print("‚úÖ Testing Configuration Validation")
    print("="*60)
    
    # Test 1: Whisper model validation
    print_test("Whisper model values")
    try:
        whisper_model = os.getenv('WHISPER_MODEL', 'small')
        valid_models = ['tiny', 'base', 'small', 'medium', 'large']
        
        if whisper_model in valid_models:
            pass_test(f"Whisper model '{whisper_model}' is valid")
        else:
            fail_test("Whisper model validation", f"Invalid model: {whisper_model}")
    except Exception as e:
        fail_test("Whisper model validation", str(e))
    
    # Test 2: Output format validation
    print_test("Output format values")
    try:
        output_format = os.getenv('OUTPUT_FORMAT', 'md')
        valid_formats = ['md', 'txt']
        
        if output_format in valid_formats:
            pass_test(f"Output format '{output_format}' is valid")
        else:
            fail_test("Output format validation", f"Invalid format: {output_format}")
    except Exception as e:
        fail_test("Output format validation", str(e))
    
    # Test 3: Boolean settings
    print_test("Boolean configuration values")
    try:
        bool_settings = {
            'AUTO_COPY': os.getenv('AUTO_COPY', 'false'),
            'AUTO_OPEN': os.getenv('AUTO_OPEN', 'false'),
            'AUTO_METADATA': os.getenv('AUTO_METADATA', 'false'),
            'AUTO_CLEANUP_AUDIO': os.getenv('AUTO_CLEANUP_AUDIO', 'true'),
            'STREAMING_VERBOSE': os.getenv('STREAMING_VERBOSE', 'false'),
        }
        
        invalid = []
        for key, value in bool_settings.items():
            if value.lower() not in ['true', 'false']:
                invalid.append(f"{key}={value}")
        
        if not invalid:
            pass_test(f"All {len(bool_settings)} boolean settings are valid")
        else:
            fail_test("Boolean validation", f"Invalid values: {', '.join(invalid)}")
    except Exception as e:
        fail_test("Boolean validation", str(e))
    
    # Test 4: Numeric settings
    print_test("Numeric configuration values")
    try:
        numeric_settings = {
            'SILENCE_DURATION_SECONDS': int(os.getenv('SILENCE_DURATION_SECONDS', '120')),
            'DEFAULT_MIC_DEVICE': int(os.getenv('DEFAULT_MIC_DEVICE', '-1')),
            'STREAMING_BUFFER_SIZE_SECONDS': int(os.getenv('STREAMING_BUFFER_SIZE_SECONDS', '300')),
            'STREAMING_MIN_SEGMENT_DURATION': int(os.getenv('STREAMING_MIN_SEGMENT_DURATION', '30')),
            'STREAMING_TARGET_SEGMENT_DURATION': int(os.getenv('STREAMING_TARGET_SEGMENT_DURATION', '60')),
            'STREAMING_MAX_SEGMENT_DURATION': int(os.getenv('STREAMING_MAX_SEGMENT_DURATION', '90')),
            'OLLAMA_TIMEOUT': int(os.getenv('OLLAMA_TIMEOUT', '180')),
            'OLLAMA_MAX_CONTENT_LENGTH': int(os.getenv('OLLAMA_MAX_CONTENT_LENGTH', '32000')),
        }
        
        print(f"   Validated {len(numeric_settings)} numeric settings")
        pass_test("All numeric settings parse correctly")
    except ValueError as e:
        fail_test("Numeric validation", f"Cannot parse numeric value: {e}")
    except Exception as e:
        fail_test("Numeric validation", str(e))
    
    # Test 5: Path validation
    print_test("Path configuration values")
    try:
        save_path = os.getenv('SAVE_PATH')
        
        if save_path and os.path.isdir(save_path):
            pass_test(f"Save path exists: {save_path}")
        elif save_path:
            fail_test("Save path validation", f"Directory not found: {save_path}")
        else:
            fail_test("Save path validation", "SAVE_PATH not set")
    except Exception as e:
        fail_test("Path validation", str(e))
    
    # Test 6: URL validation
    print_test("URL configuration values")
    try:
        ollama_url = os.getenv('OLLAMA_API_URL', 'http://localhost:11434/api/generate')
        
        if ollama_url.startswith('http://') or ollama_url.startswith('https://'):
            pass_test(f"Ollama URL format is valid")
        else:
            fail_test("URL validation", f"Invalid URL format: {ollama_url}")
    except Exception as e:
        fail_test("URL validation", str(e))

def test_streaming_settings_logic():
    """Test streaming segment duration logic"""
    print("\n" + "="*60)
    print("‚ö° Testing Streaming Settings Logic")
    print("="*60)
    
    print_test("Segment duration relationships")
    try:
        min_dur = int(os.getenv('STREAMING_MIN_SEGMENT_DURATION', '30'))
        target_dur = int(os.getenv('STREAMING_TARGET_SEGMENT_DURATION', '60'))
        max_dur = int(os.getenv('STREAMING_MAX_SEGMENT_DURATION', '90'))
        
        issues = []
        if not (min_dur < target_dur < max_dur):
            issues.append(f"Durations not in order: min={min_dur}, target={target_dur}, max={max_dur}")
        
        if min_dur < 10:
            issues.append(f"Min duration too small: {min_dur}s (should be >= 10s)")
        
        if max_dur > 120:
            issues.append(f"Max duration too large: {max_dur}s (Whisper works best <= 120s)")
        
        if issues:
            fail_test("Segment duration logic", "; ".join(issues))
        else:
            print(f"   Min: {min_dur}s ‚Üí Target: {target_dur}s ‚Üí Max: {max_dur}s")
            pass_test("Segment durations are properly ordered")
    except Exception as e:
        fail_test("Segment duration logic", str(e))
    
    # Test 2: Buffer size validation
    print_test("Buffer size appropriateness")
    try:
        buffer_size = int(os.getenv('STREAMING_BUFFER_SIZE_SECONDS', '300'))
        max_segment = int(os.getenv('STREAMING_MAX_SEGMENT_DURATION', '90'))
        
        if buffer_size < max_segment * 2:
            fail_test("Buffer size validation", 
                     f"Buffer ({buffer_size}s) should be >= 2x max segment ({max_segment}s)")
        else:
            print(f"   Buffer: {buffer_size}s ({buffer_size/60:.1f} minutes)")
            pass_test("Buffer size is appropriate")
    except Exception as e:
        fail_test("Buffer size validation", str(e))

def test_settings_module_structure():
    """Test settings module structure and organization"""
    print("\n" + "="*60)
    print("üèóÔ∏è  Testing Settings Module Structure")
    print("="*60)
    
    print_test("Settings module structure")
    try:
        import settings
        import inspect
        
        # Get all functions
        functions = [name for name, obj in inspect.getmembers(settings) 
                    if inspect.isfunction(obj) and not name.startswith('_')]
        
        # Expected functions
        expected = [
            'settings_menu',
            'transcription_settings',
            'output_settings',
            'ai_settings',
            'audio_settings',
            'advanced_performance_settings',
            'command_settings',
            'uninstall_settings',
            'update_env_setting',
            'list_audio_devices'
        ]
        
        missing = [f for f in expected if f not in functions]
        extra = [f for f in functions if f not in expected and not f.startswith('test')]
        
        if not missing:
            print(f"   Found all {len(expected)} expected functions")
            if extra:
                print(f"   Additional functions: {', '.join(extra[:5])}")
            pass_test("Settings module has all required functions")
        else:
            fail_test("Settings module structure", f"Missing: {', '.join(missing)}")
    except Exception as e:
        fail_test("Settings module structure", str(e))

def generate_report():
    """Generate test report"""
    print("\n" + "="*60)
    print("üìä SETTINGS TEST SUMMARY")
    print("="*60)
    print(f"\nTotal Tests:  {tests_total}")
    print(f"‚úÖ Passed:     {tests_passed}")
    print(f"‚ùå Failed:     {tests_failed}")
    
    if tests_total > 0:
        pass_rate = (tests_passed * 100) // tests_total
        print(f"\nPass Rate:    {pass_rate}%")
        
        if tests_failed == 0:
            print("\nüéâ All settings tests passed!")
            return 0
        else:
            print(f"\n‚ö†Ô∏è  {tests_failed} test(s) failed. Review output above.")
            return 1
    else:
        print("\n‚ö†Ô∏è  No tests were run")
        return 1

def main():
    """Run all settings tests"""
    print("="*60)
    print("üß™ REJOICE SETTINGS TEST SUITE")
    print("="*60)
    print("Testing all settings functionality without manual interaction")
    print(f"Date: {os.popen('date').read().strip()}")
    
    # Check we're in the right directory
    if not os.path.exists('src/settings.py'):
        print("‚ùå Error: Must run from rejoice-slim root directory")
        return 1
    
    # Check .env exists
    if not os.path.exists('.env'):
        print("‚ùå Error: .env file not found. Run setup.sh first.")
        return 1
    
    # Run all test suites
    test_env_file_operations()
    test_update_env_setting()
    test_settings_menu_import()
    test_audio_device_listing()
    test_configuration_validation()
    test_streaming_settings_logic()
    test_settings_module_structure()
    
    # Generate report
    return generate_report()

if __name__ == '__main__':
    sys.exit(main())
