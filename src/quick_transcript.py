# src/quick_transcript.py

import threading
import time
import subprocess
import platform
from typing import List, Dict, Optional, Callable, Tuple
import logging
from dataclasses import dataclass, asdict
from datetime import datetime
import json
import os
import numpy as np

from volume_segmenter import SegmentInfo
from transcript_manager import TranscriptFileManager
from audio_manager import AudioFileManager

logger = logging.getLogger(__name__)

@dataclass
class TranscriptionSegment:
    """Information about a transcribed segment."""
    segment_info: SegmentInfo
    transcription: str
    timestamp: float
    processing_time: float
    status: str  # 'pending', 'processing', 'completed', 'failed'
    error: Optional[str] = None

@dataclass
class QuickTranscriptResult:
    """Result of quick transcript assembly."""
    transcript_id: str
    transcript_text: str
    segments_count: int
    total_duration: float
    processing_summary: Dict
    file_path: str
    clipboard_copied: bool
    has_content: bool

class QuickTranscriptAssembler:
    """
    Assembles streaming segments into immediate transcription results.
    
    Provides instant transcript delivery with clipboard integration
    and prepares for background enhancement processing.
    """
    
    def __init__(self, 
                 transcript_manager: TranscriptFileManager,
                 audio_manager: AudioFileManager,
                 auto_clipboard: bool = True):
        """
        Initialize the quick transcript assembler.
        
        Args:
            transcript_manager: TranscriptFileManager for file operations
            audio_manager: AudioFileManager for audio storage
            auto_clipboard: Automatically copy results to clipboard
        """
        self.transcript_manager = transcript_manager
        self.audio_manager = audio_manager
        self.auto_clipboard = auto_clipboard
        
        # State management
        self.lock = threading.RLock()
        self.current_session = None
        self.final_transcript_id = None  # Actual transcript ID after saving
        self.transcription_segments: Dict[str, TranscriptionSegment] = {}
        self.segment_order: List[str] = []
        self.is_processing = False
        
        # Empty segment detection - sliding window approach
        self.recent_segment_texts = []  # Track last N segment texts
        self.empty_segment_threshold = int(os.getenv("EMPTY_SEGMENT_THRESHOLD", "3"))
        self.empty_segment_min_chars = int(os.getenv("EMPTY_SEGMENT_MIN_CHARS", "10"))
        
        # Processing tracking
        self.session_start_time = None
        self.processing_stats = {
            'segments_received': 0,
            'segments_completed': 0,
            'segments_failed': 0,
            'total_processing_time': 0.0
        }
        
        # Callbacks
        self.segment_completed_callback: Optional[Callable[[TranscriptionSegment], None]] = None
        self.transcript_ready_callback: Optional[Callable[[QuickTranscriptResult], None]] = None
        
        logger.info("QuickTranscriptAssembler initialized")
    
    def _calculate_completion_timeout(self) -> float:
        """Determine dynamic timeout for segment completion."""
        with self.lock:
            if not self.transcription_segments:
                return 10.0
            
            total_duration = sum(
                segment.segment_info.duration
                for segment in self.transcription_segments.values()
                if segment.segment_info
            )
            max_duration = max(
                segment.segment_info.duration
                for segment in self.transcription_segments.values()
                if segment.segment_info
            )
        
        base_timeout = 30.0
        duration_timeout = max_duration * 2.0
        total_timeout = total_duration * 1.5
        
        return max(base_timeout, duration_timeout, total_timeout)
    
    def start_session(self, session_id: str) -> None:
        """
        Start a new transcription session.
        
        Args:
            session_id: Unique identifier for the session
        """
        with self.lock:
            self.current_session = session_id
            self.transcription_segments = {}
            self.segment_order = []
            self.is_processing = True
            self.session_start_time = time.time()
            self.processing_stats = {
                'segments_received': 0,
                'segments_completed': 0,
                'segments_failed': 0,
                'total_processing_time': 0.0
            }
            self.consecutive_empty_count = 0
            
        logger.info(f"QuickTranscriptAssembler: Started session {session_id}")
    
    def add_segment_for_transcription(self, segment_info: SegmentInfo, audio_data) -> str:
        """
        Add a segment for transcription processing.
        
        Args:
            segment_info: SegmentInfo with timing and metadata
            audio_data: Audio data for the segment
            
        Returns:
            Segment ID for tracking
        """
        if not self.is_processing:
            logger.warning("Not in processing mode")
            return ""
            
        segment_id = f"seg_{segment_info.start_time:.1f}_{segment_info.end_time:.1f}"
        
        with self.lock:
            transcription_segment = TranscriptionSegment(
                segment_info=segment_info,
                transcription="",
                timestamp=time.time(),
                processing_time=0.0,
                status='pending'
            )
            
            self.transcription_segments[segment_id] = transcription_segment
            self.segment_order.append(segment_id)
            self.processing_stats['segments_received'] += 1
            
        logger.debug(f"Added segment for transcription: {segment_id}")
        
        # Start transcription in background thread
        threading.Thread(
            target=self._transcribe_segment,
            args=(segment_id, audio_data),
            daemon=True
        ).start()
        
        return segment_id
    
    def _transcribe_segment(self, segment_id: str, audio_data) -> None:
        """
        Transcribe a single segment using Whisper.
        
        Args:
            segment_id: Segment identifier
            audio_data: Audio data to transcribe
        """
        start_time = time.time()
        
        try:
            with self.lock:
                if segment_id not in self.transcription_segments:
                    return
                self.transcription_segments[segment_id].status = 'processing'
            
            # TODO: Integrate with existing Whisper transcription
            # For now, simulate transcription
            transcription = self._whisper_transcribe(audio_data)
            processing_time = time.time() - start_time
            
            with self.lock:
                if segment_id in self.transcription_segments:
                    segment = self.transcription_segments[segment_id]
                    segment.transcription = transcription
                    segment.processing_time = processing_time
                    segment.status = 'completed'
                    
                    self.processing_stats['segments_completed'] += 1
                    self.processing_stats['total_processing_time'] += processing_time
            
            # Trigger callback
            if self.segment_completed_callback:
                try:
                    self.segment_completed_callback(self.transcription_segments[segment_id])
                except Exception as e:
                    logger.error(f"Error in segment completion callback: {e}")
            
            # Update empty segment counter
            self._update_empty_segment_counter(transcription)
            
            logger.debug(f"Completed transcription for {segment_id}: {len(transcription)} chars")
            
        except Exception as e:
            logger.error(f"Error transcribing segment {segment_id}: {e}")
            
            with self.lock:
                if segment_id in self.transcription_segments:
                    segment = self.transcription_segments[segment_id]
                    segment.status = 'failed'
                    segment.error = str(e)
                    self.processing_stats['segments_failed'] += 1
    
    def _whisper_transcribe(self, audio_data) -> str:
        """
        Transcribe audio using Whisper.
        
        Args:
            audio_data: Audio data to transcribe (numpy array, float32, normalized)
            
        Returns:
            Transcribed text
        """
        try:
            # Import Whisper and get model settings
            import whisper
            import os
            
            WHISPER_MODEL = os.getenv("WHISPER_MODEL", "small")
            WHISPER_LANGUAGE = os.getenv("WHISPER_LANGUAGE", "auto")
            
            # Load model if not already cached
            if not hasattr(self, '_whisper_model') or self._whisper_model is None:
                logger.debug(f"Loading Whisper model: {WHISPER_MODEL}")
                self._whisper_model = whisper.load_model(WHISPER_MODEL)
            
            # Ensure audio_data is float32 numpy array
            import numpy as np
            if isinstance(audio_data, list):
                audio_data = np.array(audio_data, dtype=np.float32)
            elif not isinstance(audio_data, np.ndarray):
                audio_data = np.array(audio_data, dtype=np.float32)
            
            # Normalize if needed (should be in [-1, 1] range)
            if audio_data.dtype != np.float32:
                if np.max(np.abs(audio_data)) > 1.0:
                    audio_data = audio_data.astype(np.float32) / 32767.0
                else:
                    audio_data = audio_data.astype(np.float32)
            
            # Check minimum length
            if len(audio_data) < 1600:  # Less than 0.1 seconds at 16kHz
                return ""
            
            # Transcribe with Whisper
            if WHISPER_LANGUAGE and WHISPER_LANGUAGE.lower() != "auto":
                result = self._whisper_model.transcribe(audio_data, fp16=False, language=WHISPER_LANGUAGE)
            else:
                result = self._whisper_model.transcribe(audio_data, fp16=False)
            
            text = result["text"].strip()
            logger.debug(f"Whisper transcribed {len(audio_data)/16000:.1f}s -> '{text[:100]}...'")
            return text
            
        except Exception as e:
            logger.error(f"Whisper transcription failed: {e}")
            duration = len(audio_data) / 16000 if hasattr(audio_data, '__len__') else 0
            return f"[Transcription failed - {duration:.1f}s audio]"
    
    def get_current_transcript(self) -> str:
        """
        Get the current assembled transcript from completed segments.
        
        Returns:
            Current transcript text
        """
        with self.lock:
            transcript_parts = []
            
            for segment_id in self.segment_order:
                segment = self.transcription_segments.get(segment_id)
                if segment and segment.status == 'completed' and segment.transcription.strip():
                    transcript_parts.append(segment.transcription.strip())
            
            return ' '.join(transcript_parts)
    
    def wait_for_completion(self, timeout: float = 30.0) -> bool:
        """
        Wait for all pending segments to complete.
        
        Args:
            timeout: Maximum time to wait in seconds
            
        Returns:
            True if all segments completed, False if timeout
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            with self.lock:
                pending_count = sum(1 for s in self.transcription_segments.values() 
                                  if s.status in ['pending', 'processing'])
                
                if pending_count == 0:
                    logger.info("QuickTranscriptAssembler: All segments completed")
                    return True
            
            time.sleep(0.1)
        
        logger.warning(f"QuickTranscriptAssembler: Timeout waiting for completion ({timeout}s)")
        return False
    
    def finalize_transcript(self) -> Optional[QuickTranscriptResult]:
        """
        Finalize the transcript and create the result.
        
        Returns:
            QuickTranscriptResult with complete transcript data
        """
        if not self.current_session:
            logger.error("No active session to finalize")
            return None
        
        dynamic_timeout = self._calculate_completion_timeout()
        logger.info(f"QuickTranscriptAssembler: Waiting up to {dynamic_timeout:.1f}s for segment completion")
        self.wait_for_completion(timeout=dynamic_timeout)
        
        with self.lock:
            final_transcript = self.get_current_transcript().strip()
            has_content = bool(final_transcript)
            
            if not has_content:
                logger.warning("No transcription content available")
            
            completed_segments = [
                s for s in self.transcription_segments.values() if s.status == 'completed'
            ]
            total_duration = 0.0
            if completed_segments:
                total_duration = max(s.segment_info.end_time for s in completed_segments)
            
            processing_summary = self.processing_stats.copy()
            processing_summary['session_duration'] = time.time() - (self.session_start_time or 0)
            
            file_path = ""
            if has_content:
                try:
                    file_path = self._save_transcript_file(final_transcript, processing_summary)
                    logger.info(f"Saved quick transcript: {file_path}")
                except Exception as e:
                    logger.error(f"Failed to save transcript: {e}")
                    file_path = ""
            else:
                self.final_transcript_id = None
            
            clipboard_success = False
            if self.auto_clipboard and has_content:
                clipboard_success = self._copy_to_clipboard(final_transcript)
            
            result = QuickTranscriptResult(
                transcript_id=getattr(self, 'final_transcript_id', None) or self.current_session,
                transcript_text=final_transcript,
                segments_count=len(completed_segments),
                total_duration=total_duration,
                processing_summary=processing_summary,
                file_path=file_path,
                clipboard_copied=clipboard_success,
                has_content=has_content
            )
            
            # Trigger callback
            if self.transcript_ready_callback:
                try:
                    self.transcript_ready_callback(result)
                except Exception as e:
                    logger.error(f"Error in transcript ready callback: {e}")
            
            self.is_processing = False
            logger.info(f"QuickTranscriptAssembler: Finalized transcript {self.current_session}")
            
            return result
    
    def _save_transcript_file(self, transcript_text: str, processing_summary: Dict) -> str:
        """
        Save transcript to file with metadata.
        
        Args:
            transcript_text: The transcribed text
            processing_summary: Processing statistics
            
        Returns:
            Path to saved file
        """
        # Generate metadata
        metadata = {
            'session_id': self.current_session,
            'timestamp': datetime.now().isoformat(),
            'processing_type': 'quick_streaming',
            'segments_count': processing_summary['segments_completed'],
            'total_duration': processing_summary.get('session_duration', 0),
            'processing_stats': processing_summary
        }
        
        # Save using transcript manager
        file_path, transcript_id, _ = self.transcript_manager.create_new_transcript(
            transcript_text,
            generated_filename="streaming_transcript"
        )
        
        logger.info(f"Transcript saved to {file_path} with ID {transcript_id}")
        
        # Update the stored transcript_id to the actual file ID  
        self.final_transcript_id = transcript_id
        
        return file_path
    
    def _copy_to_clipboard(self, text: str) -> bool:
        """
        Copy text to system clipboard.
        
        Args:
            text: Text to copy
            
        Returns:
            True if successful, False otherwise
        """
        try:
            system = platform.system().lower()
            
            if system == 'darwin':  # macOS
                process = subprocess.Popen(['pbcopy'], stdin=subprocess.PIPE)
                process.communicate(input=text.encode('utf-8'))
            elif system == 'linux':
                process = subprocess.Popen(['xclip', '-selection', 'clipboard'], stdin=subprocess.PIPE)
                process.communicate(input=text.encode('utf-8'))
            elif system == 'windows':
                process = subprocess.Popen(['clip'], stdin=subprocess.PIPE, shell=True)
                process.communicate(input=text.encode('utf-8'))
            else:
                logger.warning(f"Clipboard copy not supported on {system}")
                return False
            
            logger.info("Successfully copied transcript to clipboard")
            return True
            
        except Exception as e:
            logger.error(f"Failed to copy to clipboard: {e}")
            return False
    
    def set_segment_completed_callback(self, callback: Callable[[TranscriptionSegment], None]) -> None:
        """Set callback for when individual segments complete."""
        self.segment_completed_callback = callback
        logger.info("QuickTranscriptAssembler: Segment completion callback set")
    
    def set_transcript_ready_callback(self, callback: Callable[[QuickTranscriptResult], None]) -> None:
        """Set callback for when complete transcript is ready."""
        self.transcript_ready_callback = callback
        logger.info("QuickTranscriptAssembler: Transcript ready callback set")
    
    def get_progress_stats(self) -> Dict:
        """Get current progress statistics."""
        with self.lock:
            stats = self.processing_stats.copy()
            stats['session_id'] = self.current_session
            stats['is_processing'] = self.is_processing
            stats['current_transcript_length'] = len(self.get_current_transcript())
            
            # Calculate completion percentage
            total_segments = stats['segments_received']
            if total_segments > 0:
                completed_ratio = stats['segments_completed'] / total_segments
                stats['completion_percentage'] = int(completed_ratio * 100)
            else:
                stats['completion_percentage'] = 0
            
            return stats
    
    def _update_empty_segment_counter(self, transcription: str) -> None:
        """Update recent segment texts for sliding window analysis.
        
        Args:
            transcription: The transcribed text from the segment
        """
        with self.lock:
            # Add this segment's text to our sliding window
            self.recent_segment_texts.append(transcription.strip() if transcription else "")
            
            # Keep only the last N segments
            if len(self.recent_segment_texts) > self.empty_segment_threshold:
                self.recent_segment_texts.pop(0)
            
            logger.debug(f"Added segment text (len={len(transcription.strip() if transcription else '')}). Window size: {len(self.recent_segment_texts)}/{self.empty_segment_threshold}")
    
    def should_auto_stop(self) -> Tuple[bool, str]:
        """Check if we should auto-stop based on last N segments combined text.
        
        Returns:
            Tuple of (should_stop, reason_message)
        """
        with self.lock:
            # Need at least N segments to check
            if len(self.recent_segment_texts) < self.empty_segment_threshold:
                return False, ""
            
            # Combine the last N segments
            combined_text = " ".join(self.recent_segment_texts).strip()
            combined_length = len(combined_text)
            
            logger.debug(f"Combined last {self.empty_segment_threshold} segments: {combined_length} chars")
            logger.debug(f"Preview: '{combined_text[:100]}...'") if combined_text else logger.debug("Combined text is empty")
            
            # Check if combined text is below threshold
            if combined_length < self.empty_segment_min_chars:
                reason = f"Last {self.empty_segment_threshold} segments combined have < {self.empty_segment_min_chars} chars ({combined_length} chars)"
                logger.info(f"Auto-stop triggered: {reason}")
                return True, reason
            
            return False, ""
    
    def get_consecutive_empty_segments(self) -> int:
        """Get the current count of consecutive empty segments (deprecated).
        
        Returns:
            Number of consecutive empty segments (for backwards compatibility)
        """
        with self.lock:
            # For backwards compatibility, return 0 if we have content, threshold if we should stop
            should_stop, _ = self.should_auto_stop()
            return self.empty_segment_threshold if should_stop else 0

class QuickTranscriptDisplay:
    """Helper for displaying real-time transcription progress."""
    
    @staticmethod
    def format_progress_line(assembler: QuickTranscriptAssembler) -> str:
        """Format a progress line for display."""
        stats = assembler.get_progress_stats()
        
        if not stats['is_processing']:
            return "ğŸ“ Transcription ready"
        
        completed = stats['segments_completed']
        total = stats['segments_received']
        percentage = stats['completion_percentage']
        
        if total == 0:
            return "ğŸ“ Waiting for audio segments..."
        
        return f"ğŸ“ Transcribing: {completed}/{total} segments ({percentage}%)"
    
    @staticmethod
    def format_segment_update(segment: TranscriptionSegment) -> str:
        """Format a segment completion update."""
        duration = segment.segment_info.duration
        text_preview = segment.transcription[:50] + "..." if len(segment.transcription) > 50 else segment.transcription
        
        return f"ğŸ“ Segment {duration:.1f}s: \"{text_preview}\""
    
    @staticmethod
    def format_final_result(result: QuickTranscriptResult) -> List[str]:
        """Format the final result announcement."""
        if not result.has_content:
            lines = [
                "âš ï¸ Streaming transcript not ready",
                "ğŸ”„ Falling back to full audio transcription..."
            ]
            if result.file_path:
                lines.append(f"ğŸ“ Saved: {os.path.basename(result.file_path)}")
            return lines
        
        lines = [
            "âœ… Recording complete!",
            f"ğŸ“ Transcript: {len(result.transcript_text)} characters",
            f"â±ï¸  Duration: {result.total_duration:.1f} seconds",
            f"ğŸ”¢ Segments: {result.segments_count}"
        ]
        
        if result.clipboard_copied:
            lines.append("ğŸ“‹ Transcript copied to clipboard")
        
        if result.file_path:
            lines.append(f"ğŸ“ Saved: {os.path.basename(result.file_path)}")
        
        return lines